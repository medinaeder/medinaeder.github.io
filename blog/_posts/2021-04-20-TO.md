---
layout: post
title: Topology Optimization
---

In this post I will demonstrate how to solve a topology optimization problem. Topology optimization problems attempt to find the distribution of material within some domain such that some property is extremized.


The control variable is the density of the material $\rho$ which determines the effective material properties.  The goal is to design a structure that uses less than half of the initial domains volume but does not easily shear. This will take the form of a PDE-Constrained optimization
$$
\begin{align} 
\min_{\rho \in \mathcal L^2 } && J(u, \rho) \nonumber \\
\text{s.t.} \; && R(u;\rho) = 0 \nonumber\\ 
&& 0 \leq \rho \leq 1, \nonumber 
\end{align}
$$

Here we will use the SIMP method which allows density is allows the density to vary continuously $\rho \in [0,1]$ and whose material property (youngs modulus $E$)follows a power law with respect to density

$ E = E_0 + (E_max - E_0)\rho^p $

The power law is said to promote material towards the bounds, i.e. it penalizes intermediate densities. This will give us a design is black and white. I find that this result is rather unintuitive. Why does a power penalize intermediate densities? The best way I have found to think about this is to think of the volume constraint as being a bank. I have a maximum budget of material that I want to spend. The stiffness of the material will obey a power law which says that the denser material gives me more bang(stiffness) for my buck (volume constraint). Material is cheaper when you buy in bulk. To prevent heckboarding patterns often found in the standard TO problem, we will filter our control twice -- first through a helmholtz filter and then through a thresholding filtering.

We will be optimizing the shearing stiffness of a square domain. I.e. we want the force to for an applied displacement to be as large as possible or we want the displacement for a given force to be as small as possible. This quantity if it is the only external work being done on our structure will be equivalent to the structures internal strain energy. Thus depending on the the type of boundary conditions used we will maximize or minimize strain energy. 


I will also demonstrate how to use [NLopt](https://nlopt.readthedocs.io/en/latest/). NLopt is written by Steven Johnson at MIT and offers a consistent interface for different optimization algorithms. This will be useful when trying to find out which algorithm works best for your problem. The one limitation is that it only works in serial. Once problems become larger I would recommend using another optimization library such as [IPOPT](https://coin-or.github.io/Ipopt/) or [ROL](https://trilinos.github.io/rol.html) (with a strong preference towards ROL). 



Let's begin with all the imports.


```python
import nlopt
import numpy as np
from firedrake import *
from firedrake_adjoint import *
from firedrake.petsc import PETSc
import matplotlib.pyplot as plt

import os

from pyadjoint import no_annotations
from pyadjoint.reduced_functional_numpy import ReducedFunctionalNumPy
import time

set_log_level('ERROR')
from tqdm import tqdm
```

Now we will define some of the parameters in our problem and our constitutive model. 


```python
V_lim = Constant(0.5)  # volume bound on the control
p = Constant(5)  # power used in the solid isotropic material
# with penalisation (SIMP) rule, to encourage the control
# solution to attain either 0 or 1
epss = Constant(1.0e-3)

def k(a):
    """Solid isotropic material with penalisation (SIMP) conductivity
    rule, equation (11)."""
    return epss + (1 - epss) * a **p


def eps(r):
    return sym(grad(r))


def sigma(r):
    E = Constant(1.0e2)
    nu = 0.3
    mu = E / (2 * (1 + nu))
    lmbda = E * nu / ((1.0 + nu) * (1.0 - 2.0 * nu))
    return 2.0 * mu * sym(grad(r)) + lmbda * tr(sym(grad(r))) * Identity(len(r))
```

Some containers to analyze the progress of our algorithm. 


```python
objectives = []
volumes = []
```


```python
max_iterations = 50
pbar = tqdm(total=max_iterations);
```

      0%|                                                                                                                                                                  | 0/50 [00:00<?, ?it/s]


```python
# Shortening some verbose firedrake commands
NVP = NonlinearVariationalProblem
NVS = NonlinearVariationalSolver
```

Here is the meat of the problem. This is where we will define the PDE that we are trying to solve and write the interface to pyadjoint to compute the gradient of our objective with respect to our control.

We will work on a square domain with quadrilateral elements. 
We will create a series of nested meshes in order to use the best iterative solver for linear elliptic problems known as multigrid. I will actually not use vanilla mg but rather will do use a multigrid preconditioned conjugate gradient. 

Having written 1D and 2D multigrid codes in the past, I am so glad that this has been automated by the firedrake developers. In order to specify a geometric multigrid algorithm one simply needs to construct a series of nested meshes and specify `mg` as the preconditioner. I really like firedrake. 


```python
class ElasticityProblem(object):
    def __init__(self, N, nref):
        base = RectangleMesh(N, N, 1, 1,quadrilateral=True)
        #base = Mesh("base.msh")
        start = time.perf_counter()
        mh = MeshHierarchy(base, nref)
        mesh = mh[-1]
        self.mesh = mesh
        # function space for control
        A = FunctionSpace(mesh, "CG", 1)
        print("Control Size", A.dim())
        self.A = A
        rho = Function(A, name="Control")
        rho.interpolate(Constant(0.5))

        # function space for solution
        V = VectorFunctionSpace(mesh, "CG", 1)
        end = time.perf_counter()
        print(f"Meshing Time {end-start}")
        sp = {
            "snes_type": "ksponly",
            "snes_max_linear_solve_fail": 100,
            "snes_max_it": 100,
            "snes_dtol": 1e10,
            "snes_atol": 1e-9,
            "snes_rtol": 1e-10,
            "ksp_type": "cg",
            "pc_type": "mg",
            "mg_coarse_ksp_type": "preonly",
            "mg_coarse_pc_type": "lu",
            "mg_coarse_pc_factor_mat_solver_type": "mumps",
            "mat_type": "aij",
        }
        rho_hat = Function(A)
        r_t = TestFunction(A)
        rf = Constant(0.02)
        beta = Constant(10.5)
        r_f = Function(A)

        (x, y) = SpatialCoordinate(mesh)
        df = 0.08
        F_helmholtz = (
            inner(rf**2 * grad(rho_hat), grad(r_t)) * dx
            + rho_hat * r_t * dx
            - rho * r_t * dx
        )
        fh_problem = NVP(F_helmholtz, rho_hat, bcs=[])
        fh_solver = NVS(fh_problem, solver_parameters=sp)
        fh_solver.solve()

        r_f.assign(
            Constant(0.5) + tanh(beta * (rho_hat - 0.5)) / (2 * tanh(0.5 * beta))
        )

        u = Function(V)
        self.u = u
        v = TestFunction(V)
        a = inner(k(r_f) * sigma(u), eps(v)) * dx
        F_elasticity = a

        bcs = [DirichletBC(V, Constant((-1e-3, 0)), 3),
                DirichletBC(V, Constant((1e-3, 0)), 4)]

        problem = NVP(F_elasticity, u, bcs=bcs)
        solver = NVS(problem,solver_parameters=sp)
        solver.solve()
        jform = (-inner(k(r_f) * sigma(u), eps(u)) * dx)

        J = assemble(jform)
        m = Control(rho)
        self.u_c = Control(u)
        self.r_c = Control(r_f)

        Jc = assemble(r_f * dx)

        self.rf_np = ReducedFunctionalNumPy(ReducedFunctional(J, m))
        self.rf_np_c = ReducedFunctionalNumPy(ReducedFunctional(Jc, m))
        self.count = 0
        

    @no_annotations
    def __call__(self, x, grad):
        f = self.rf_np(x)

        if grad.size > 0:
            grad[:] = self.rf_np.derivative()

        self.count += 1
        objectives.append(f)
        pbar.update(1)
        return f

```

There are some parts that may look strange such as the `@no_annotations` decorator. This will prevent the pyadjoint tape from getting to big. The tape is the computational graph that pyadjoint is keeping to differentiate the program. I believe that it is actually not necessary for the problem above because none of the operators are actually interacting with firedrake specific variables but it doesn't hurt. 

Here we will specify a way to compute the constraint. It takes in the reduced functional that we previously computed in the main elasticity problem. The two objects should really be decoupled and solely share a dependence on the control. 


```python
class VolumeConstraint(object):
    def __init__(self, rf_np, Vol):
        self.V = Vol
        self.rf_np = rf_np

    def __call__(self, x, grad):
        f = self.rf_np(x)
        volumes.append(f)
        # self.outfile.write(self.a)
        if grad.size > 0:
            grad[:] = self.rf_np.derivative()
        f -= float(self.V)
        return f
```

Let's now solve the problem once to generate the computational graph and get a feel for how long the solver should truly take. It will also tell us how many control variables we actually have. 


```python
nref = 8
start = time.perf_counter()
p = ElasticityProblem(2, nref)
end = time.perf_counter()
print(f"Total Time {end-start}")
```

    Control Size 66049
    Meshing Time 1.07557742499921
    Total Time 3.936639113999263


Hey not bad! We are at about 3 seconds for our forward solve. Thus each optimization iteration should take approximately 6 seconds. I can live with that. I can live with that because we see that we have ~66k variables to optimize for. 

## Mesh


```python
plt.figure(figsize=(15,15))
triplot(p.mesh,axes=plt.gca());
```


    
![png](/images/TO_files/TO_18_0.png)
    


## Initial Density


```python
plt.figure(figsize=(10,10))
f = tricontourf(p.r_c.tape_value(),axes = plt.gca(),cmap="bone_r")
plt.colorbar(f);
```


    
![png](/images/TO_files/TO_20_0.png)
    



```python
print("Problem Size", p.mesh.coordinates.function_space().dim())
```

    Problem Size 132098


## Interface with NLopt


```python
m = [p0.data() for p0 in p.rf_np.controls]
# The global control vector
x0 = p.rf_np.obj_to_array(m)

c = VolumeConstraint(p.rf_np_c, V_lim)
ns = len(x0)
opt = nlopt.opt(nlopt.LD_MMA, ns)
opt.set_min_objective(p)
opt.set_lower_bounds(0)
opt.set_upper_bounds(1.0)
opt.add_inequality_constraint(c, 1e-9)
opt.set_maxeval(max_iterations)
x = opt.optimize(x0)
pbar.close()
```

    100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 50/50 [04:35<00:00,  5.50s/it]


Wow! 50 iterations took less than 5 minutes! 

Each iteration took approximately the 6 seconds that I expected. 

## Optimal Design


```python
plt.figure(figsize=(15,15))
ax = plt.gca()
f = tricontourf(p.r_c.tape_value(),axes=ax,cmap='bone_r')
plt.colorbar(f);
```


    
![png](/images/TO_files/TO_26_0.png)
    


The optimal looks like a truss design! I can convince myself that this makes sense. 


```python
plt.figure(figsize=(15,15));
quiver(p.u_c.tape_value()*p.r_c.tape_value(),axes=plt.gca());
plt.title("Displacement");
```


    
![png](/images/TO_files/TO_28_0.png)
    


# Optimization Algorithm History


```python
with plt.style.context('fivethirtyeight'):
    plt.plot(objectives)
    plt.xlabel("Iteratitons")
    plt.ylabel("Objective Value")
```


    
![png](/images/TO_files/TO_30_0.png)
    



```python
with plt.style.context('fivethirtyeight'):
    plt.plot(volumes)
    plt.gca().set_ylim(float(V_lim)*0.9,float(V_lim)*1.1)
    plt.xlabel("Iterations")
    plt.ylabel("Volume")
```


    
![png](/images/TO_files/TO_31_0.png)
    

