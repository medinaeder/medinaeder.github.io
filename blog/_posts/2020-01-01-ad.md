---
layout: post
title: Automatic Differentiation Happy Accident
---

My relationship with automatic differentiation had quite a dumb start. 
In retrospect, it is embarrassing but also goes to show that ignorance can bring innovation. 

I first learned about automatic differentiation during my REU at Stanford(Summer 2013). 
It was an interesting experience. 
I was very much a land turtle thrown into the sea. 

My first task was to read about the finite element method and write some code. 
I was to learn the basics (weak form, assembling of vectors, stiffness matrix, etc) and I got stuck within the first couple of paragraphs. 
When you solve a problem with FEM, you are given a set of basis functions, and depending on the PDE that you are trying to solve you will need to compute the derivatives of those basis functions.

Here is where I got stuck. 
"How does one compute arbitrary derivatives of some function automatically? How does a computer take a derivative?" I know how to compute derivatives for some functions but how can I get a computer to do it?
If you pose this question to your preferred search engine you will get the following results
- Finite Difference Methods
- Symbolic Differentiation
- Automatic Differentiation

Sometimes people like to say that automatic differentiation and algorithmic differentiation are different. I have never understood how these differ and a quick search gives me the impression that the AD community has begun to suggest that they are in fact the same. 

Finite difference methods are slow for a program with a large number of variables. Symbolic differentiation and automatic differentiation (AD) are both algorithmic implementations of the chain rule. 
Their differences come from the types of objects they operate on. 
I like to think that symbolic differentiation acts on symbolic variables and you get the exact mathematical expression for the derivative of a function. 
This is what sympy does. 
While AD acts on computational blocks and gives only the value of the derivative at a specific point. 
Mathematically, the two should be the same but their implementation is different.


After that summer, I didn't keep up with AD nor did I touch the code that I had worked on. 
And to my surprise when I arrived in grad school, automatic differentiation seemed to be taking the world by storm thanks due to its success in ML.
It was a pleasant surprise. 

Anywho, it turns out that the answer to my original question is a lot simpler. And it does not require automatic differentiation. In FEM you know your basis functions and you also know their derivative analytically. An efficient program will then just precompute these quantities on a reference domain, apply a mapping to the physical domain, and then assemble all relevant objects. 
I think that there are parts where AD can be used with FEM but it is not where my initial search had let me. 

